{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6172ff9b",
   "metadata": {},
   "source": [
    "# 환경변수 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad55ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e8b85",
   "metadata": {},
   "source": [
    "# STT(Speech to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83cd885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft 사운드 매퍼 - Input', '마이크 배열(디지털 마이크용 인텔® 스마트 사운드 기술)', 'CABLE Output(VB-Audio Virtual C', 'Microsoft 사운드 매퍼 - Output', 'LS27F61x(3- HD Audio Driver for', 'CABLE In 16ch(VB-Audio Virtual ', 'CABLE Input(VB-Audio Virtual Ca', '스피커(Realtek(R) Audio)', '주 사운드 캡처 드라이버', '마이크 배열(디지털 마이크용 인텔® 스마트 사운드 기술)', 'CABLE Output(VB-Audio Virtual Cable)', '주 사운드 드라이버', 'LS27F61x(3- HD Audio Driver for Display Audio)', 'CABLE In 16ch(VB-Audio Virtual Cable)', 'CABLE Input(VB-Audio Virtual Cable)', '스피커(Realtek(R) Audio)', 'LS27F61x(3- HD Audio Driver for Display Audio)', 'CABLE In 16ch(VB-Audio Virtual Cable)', 'CABLE Input(VB-Audio Virtual Cable)', '스피커(Realtek(R) Audio)', 'CABLE Output(VB-Audio Virtual Cable)', '마이크 배열(디지털 마이크용 인텔® 스마트 사운드 기술)', 'CABLE Output (VB-Audio Point)', 'Output (VB-Audio Point)', 'Input (VB-Audio Point)', '스테레오 믹스 (Realtek HD Audio Stereo input)', 'Headphones 1 (Realtek HD Audio 2nd output with SST)', 'Headphones 2 (Realtek HD Audio 2nd output with SST)', 'PC 스피커 (Realtek HD Audio 2nd output with SST)', 'Speakers 1 (Realtek HD Audio output with SST)', 'Speakers 2 (Realtek HD Audio output with SST)', 'PC 스피커 (Realtek HD Audio output with SST)', '마이크 (Realtek HD Audio Mic input)', '마이크 배열 1 ()', '마이크 배열 2 ()', '마이크 배열 3 ()', 'Output 1 (BT LE Headphones)', 'Output 2 (BT LE Headphones)', 'Input (BT LE Headphones)', '머리에 거는 수화기 (BT LE Microphone)', 'LS27F61x (ACX HD Audio Speaker)']\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.Microphone.list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2c55778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "말해주세요:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m말해주세요:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m r.adjust_for_ambient_noise(source,duration=\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# 주변 소음 조정\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m audio = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# STEP1: 마이크 입력 받기\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m인식 중입니다.....\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m text = r.recognize_openai(audio) \u001b[38;5;66;03m# STEP2: 텍스트 변환\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:530\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time - phrase_start_time > phrase_time_limit:\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    532\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# uv add pyaudio speechrecognition pydub\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer() \n",
    "# 실습 해보면서 넣을 수 있는 옵션 구글링 해보기.\n",
    "with sr.Microphone(device_index=1) as source:\n",
    "    print(\"말해주세요:\")\n",
    "    r.adjust_for_ambient_noise(source,duration=1) # 주변 소음 조정\n",
    "    audio = r.listen(source)         # STEP1: 마이크 입력 받기\n",
    "    print(\"인식 중입니다.....\")\n",
    "    text = r.recognize_openai(audio) # STEP2: 텍스트 변환\n",
    "    print(f\"인식된 텍스트: {text}\")\n",
    "\n",
    "    # STEP3: 마이크에 입력된 오디오 녹음하기\n",
    "    audio_file = audio.get_wav_data()\n",
    "    with open(\"./data/input.wav\", \"wb\") as f:\n",
    "        f.write(audio_file)\n",
    "    print(\"목소리 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cd1d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오디오 출력하기 \n",
    "from pydub import AudioSegment \n",
    "from pydub.playback import play\n",
    "\n",
    "sound = AudioSegment.from_wav(\"./data/input.wav\")\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24e985",
   "metadata": {},
   "source": [
    "# LLM 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af400b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chat(user_text):\n",
    "    system_prompt = \"\"\"당신은 시니컬한 챗봇입니다. 항상 50자 이내로 말해주세요\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1325e1",
   "metadata": {},
   "source": [
    "# 챗봇과 대화해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    r = sr.Recognizer() \n",
    "    # 실습 해보면서 넣을 수 있는 옵션 구글링 해보기.\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"말해주세요:\")\n",
    "        r.adjust_for_ambient_noise(source) # 주변 소음 조정\n",
    "        audio = r.listen(source)         # STEP1: 마이크 입력 받기\n",
    "        print(\"인식 중입니다.....\")\n",
    "        user_text = r.recognize_openai(audio) # STEP2: 텍스트 변환\n",
    "        print(f\"인식된 텍스트: {user_text}\")\n",
    "\n",
    "        if user_text == \"그만\":\n",
    "            break\n",
    "\n",
    "        answer = chat(user_text)\n",
    "        print(f\"챗봇 답변: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d38fd46",
   "metadata": {},
   "source": [
    "# TTS(Text to Speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbb7d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42c78dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"coral\",\n",
    "    input=\"안녕하세요. 반가워요!!!!!\",\n",
    "    instructions=\"너는 미국 사람인데 서툴은 한국말이며 나이는 29살이고 특이한 목소리를 가진 사람입니다. 엄청 화난 목소리야 세상에서 무엇보다\"\n",
    ") as response:\n",
    "    response.stream_to_file(\"./data/speech.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1965aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment \n",
    "from pydub.playback import play \n",
    "\n",
    "sound = AudioSegment.from_mp3(\"./data/speech.mp3\")\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326ef05",
   "metadata": {},
   "source": [
    "# 인공지능스피커 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a5867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "듣는 중....\n",
      "인식 중입니다.....\n",
      "인식된 텍스트: You\n",
      "챗봇 답변: 뭐, 필요한 거라도 있나?\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\tmpejh7c9kq.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m sound = AudioSegment.from_mp3(temp_path)\n\u001b[32m     37\u001b[39m play(sound)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] 다른 프로세스가 파일을 사용 중이기 때문에 프로세스가 액세스 할 수 없습니다: 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\tmpejh7c9kq.mp3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "while True:\n",
    "    r = sr.Recognizer() \n",
    "    # 실습 해보면서 넣을 수 있는 옵션 구글링 해보기.\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"📢 듣는 중....\")\n",
    "        # STEP 1. 마이크로부터 입력\n",
    "        r.adjust_for_ambient_noise(source) \n",
    "        audio = r.listen(source)         \n",
    "        print(\"인식 중입니다.....\")\n",
    "\n",
    "        # STEP 2. Whisper API를 통한 텍스트 변환\n",
    "        user_text = r.recognize_openai(audio) \n",
    "        print(f\"인식된 텍스트: {user_text}\")\n",
    "\n",
    "        if user_text == \"그만\":\n",
    "            break\n",
    "        \n",
    "        # STEP 3. 인공지능 챗봇 응답\n",
    "        answer = chat(user_text)\n",
    "        print(f\"챗봇 답변: {answer}\")\n",
    "\n",
    "        # STEP 4. Whisper API로 응답\n",
    "        with client.audio.speech.with_streaming_response.create(\n",
    "            model=\"gpt-4o-mini-tts\",\n",
    "            voice=\"coral\",\n",
    "            input=answer,\n",
    "            instructions=\"밝은 목소리로 말해줘\"\n",
    "        ) as response:\n",
    "            # 음성 합성 결과를 임시 파일로 저장\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_file:\n",
    "                temp_path = temp_file.name\n",
    "                response.stream_to_file(temp_path)\n",
    "\n",
    "                # 재생\n",
    "                sound = AudioSegment.from_mp3(temp_path)\n",
    "                play(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152716d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poten_up09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
