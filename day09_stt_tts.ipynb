{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6172ff9b",
   "metadata": {},
   "source": [
    "# í™˜ê²½ë³€ìˆ˜ ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad55ba72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv \n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1e8b85",
   "metadata": {},
   "source": [
    "# STT(Speech to Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83cd885a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Microsoft ì‚¬ìš´ë“œ ë§¤í¼ - Input', 'ë§ˆì´í¬ ë°°ì—´(ë””ì§€í„¸ ë§ˆì´í¬ìš© ì¸í…”Â® ìŠ¤ë§ˆíŠ¸ ì‚¬ìš´ë“œ ê¸°ìˆ )', 'CABLE Output(VB-Audio Virtual C', 'Microsoft ì‚¬ìš´ë“œ ë§¤í¼ - Output', 'LS27F61x(3- HD Audio Driver for', 'CABLE In 16ch(VB-Audio Virtual ', 'CABLE Input(VB-Audio Virtual Ca', 'ìŠ¤í”¼ì»¤(Realtek(R) Audio)', 'ì£¼ ì‚¬ìš´ë“œ ìº¡ì²˜ ë“œë¼ì´ë²„', 'ë§ˆì´í¬ ë°°ì—´(ë””ì§€í„¸ ë§ˆì´í¬ìš© ì¸í…”Â® ìŠ¤ë§ˆíŠ¸ ì‚¬ìš´ë“œ ê¸°ìˆ )', 'CABLE Output(VB-Audio Virtual Cable)', 'ì£¼ ì‚¬ìš´ë“œ ë“œë¼ì´ë²„', 'LS27F61x(3- HD Audio Driver for Display Audio)', 'CABLE In 16ch(VB-Audio Virtual Cable)', 'CABLE Input(VB-Audio Virtual Cable)', 'ìŠ¤í”¼ì»¤(Realtek(R) Audio)', 'LS27F61x(3- HD Audio Driver for Display Audio)', 'CABLE In 16ch(VB-Audio Virtual Cable)', 'CABLE Input(VB-Audio Virtual Cable)', 'ìŠ¤í”¼ì»¤(Realtek(R) Audio)', 'CABLE Output(VB-Audio Virtual Cable)', 'ë§ˆì´í¬ ë°°ì—´(ë””ì§€í„¸ ë§ˆì´í¬ìš© ì¸í…”Â® ìŠ¤ë§ˆíŠ¸ ì‚¬ìš´ë“œ ê¸°ìˆ )', 'CABLE Output (VB-Audio Point)', 'Output (VB-Audio Point)', 'Input (VB-Audio Point)', 'ìŠ¤í…Œë ˆì˜¤ ë¯¹ìŠ¤ (Realtek HD Audio Stereo input)', 'Headphones 1 (Realtek HD Audio 2nd output with SST)', 'Headphones 2 (Realtek HD Audio 2nd output with SST)', 'PC ìŠ¤í”¼ì»¤ (Realtek HD Audio 2nd output with SST)', 'Speakers 1 (Realtek HD Audio output with SST)', 'Speakers 2 (Realtek HD Audio output with SST)', 'PC ìŠ¤í”¼ì»¤ (Realtek HD Audio output with SST)', 'ë§ˆì´í¬ (Realtek HD Audio Mic input)', 'ë§ˆì´í¬ ë°°ì—´ 1 ()', 'ë§ˆì´í¬ ë°°ì—´ 2 ()', 'ë§ˆì´í¬ ë°°ì—´ 3 ()', 'Output 1 (BT LE Headphones)', 'Output 2 (BT LE Headphones)', 'Input (BT LE Headphones)', 'ë¨¸ë¦¬ì— ê±°ëŠ” ìˆ˜í™”ê¸° (BT LE Microphone)', 'LS27F61x (ACX HD Audio Speaker)']\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.Microphone.list_microphone_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f2c55778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë§í•´ì£¼ì„¸ìš”:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33më§í•´ì£¼ì„¸ìš”:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m r.adjust_for_ambient_noise(source,duration=\u001b[32m1\u001b[39m) \u001b[38;5;66;03m# ì£¼ë³€ ì†ŒìŒ ì¡°ì •\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m audio = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m         \u001b[38;5;66;03m# STEP1: ë§ˆì´í¬ ì…ë ¥ ë°›ê¸°\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mì¸ì‹ ì¤‘ì…ë‹ˆë‹¤.....\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m text = r.recognize_openai(audio) \u001b[38;5;66;03m# STEP2: í…ìŠ¤íŠ¸ ë³€í™˜\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:460\u001b[39m, in \u001b[36mRecognizer.listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    458\u001b[39m result = \u001b[38;5;28mself\u001b[39m._listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:530\u001b[39m, in \u001b[36mRecognizer._listen\u001b[39m\u001b[34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[39m\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time - phrase_start_time > phrase_time_limit:\n\u001b[32m    528\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m530\u001b[39m buffer = \u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[32m    532\u001b[39m frames.append(buffer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\speech_recognition\\__init__.py:191\u001b[39m, in \u001b[36mMicrophone.MicrophoneStream.read\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpyaudio_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\pyaudio\\__init__.py:570\u001b[39m, in \u001b[36mread\u001b[39m\u001b[34m(self, num_frames, exception_on_overflow)\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# uv add pyaudio speechrecognition pydub\n",
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer() \n",
    "# ì‹¤ìŠµ í•´ë³´ë©´ì„œ ë„£ì„ ìˆ˜ ìˆëŠ” ì˜µì…˜ êµ¬ê¸€ë§ í•´ë³´ê¸°.\n",
    "with sr.Microphone(device_index=1) as source:\n",
    "    print(\"ë§í•´ì£¼ì„¸ìš”:\")\n",
    "    r.adjust_for_ambient_noise(source,duration=1) # ì£¼ë³€ ì†ŒìŒ ì¡°ì •\n",
    "    audio = r.listen(source)         # STEP1: ë§ˆì´í¬ ì…ë ¥ ë°›ê¸°\n",
    "    print(\"ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤.....\")\n",
    "    text = r.recognize_openai(audio) # STEP2: í…ìŠ¤íŠ¸ ë³€í™˜\n",
    "    print(f\"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}\")\n",
    "\n",
    "    # STEP3: ë§ˆì´í¬ì— ì…ë ¥ëœ ì˜¤ë””ì˜¤ ë…¹ìŒí•˜ê¸°\n",
    "    audio_file = audio.get_wav_data()\n",
    "    with open(\"./data/input.wav\", \"wb\") as f:\n",
    "        f.write(audio_file)\n",
    "    print(\"ëª©ì†Œë¦¬ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cd1d6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜¤ë””ì˜¤ ì¶œë ¥í•˜ê¸° \n",
    "from pydub import AudioSegment \n",
    "from pydub.playback import play\n",
    "\n",
    "sound = AudioSegment.from_wav(\"./data/input.wav\")\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f24e985",
   "metadata": {},
   "source": [
    "# LLM ì—°ê²°í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6af400b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def chat(user_text):\n",
    "    system_prompt = \"\"\"ë‹¹ì‹ ì€ ì‹œë‹ˆì»¬í•œ ì±—ë´‡ì…ë‹ˆë‹¤. í•­ìƒ 50ì ì´ë‚´ë¡œ ë§í•´ì£¼ì„¸ìš”\"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-nano\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_text}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1325e1",
   "metadata": {},
   "source": [
    "# ì±—ë´‡ê³¼ ëŒ€í™”í•´ë³´ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb4747f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    r = sr.Recognizer() \n",
    "    # ì‹¤ìŠµ í•´ë³´ë©´ì„œ ë„£ì„ ìˆ˜ ìˆëŠ” ì˜µì…˜ êµ¬ê¸€ë§ í•´ë³´ê¸°.\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"ë§í•´ì£¼ì„¸ìš”:\")\n",
    "        r.adjust_for_ambient_noise(source) # ì£¼ë³€ ì†ŒìŒ ì¡°ì •\n",
    "        audio = r.listen(source)         # STEP1: ë§ˆì´í¬ ì…ë ¥ ë°›ê¸°\n",
    "        print(\"ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤.....\")\n",
    "        user_text = r.recognize_openai(audio) # STEP2: í…ìŠ¤íŠ¸ ë³€í™˜\n",
    "        print(f\"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {user_text}\")\n",
    "\n",
    "        if user_text == \"ê·¸ë§Œ\":\n",
    "            break\n",
    "\n",
    "        answer = chat(user_text)\n",
    "        print(f\"ì±—ë´‡ ë‹µë³€: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d38fd46",
   "metadata": {},
   "source": [
    "# TTS(Text to Speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cbb7d0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "42c78dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI \n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"coral\",\n",
    "    input=\"ì•ˆë…•í•˜ì„¸ìš”. ë°˜ê°€ì›Œìš”!!!!!\",\n",
    "    instructions=\"ë„ˆëŠ” ë¯¸êµ­ ì‚¬ëŒì¸ë° ì„œíˆ´ì€ í•œêµ­ë§ì´ë©° ë‚˜ì´ëŠ” 29ì‚´ì´ê³  íŠ¹ì´í•œ ëª©ì†Œë¦¬ë¥¼ ê°€ì§„ ì‚¬ëŒì…ë‹ˆë‹¤. ì—„ì²­ í™”ë‚œ ëª©ì†Œë¦¬ì•¼ ì„¸ìƒì—ì„œ ë¬´ì—‡ë³´ë‹¤\"\n",
    ") as response:\n",
    "    response.stream_to_file(\"./data/speech.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1965aa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment \n",
    "from pydub.playback import play \n",
    "\n",
    "sound = AudioSegment.from_mp3(\"./data/speech.mp3\")\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326ef05",
   "metadata": {},
   "source": [
    "# ì¸ê³µì§€ëŠ¥ìŠ¤í”¼ì»¤ ë§Œë“¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8a5867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë“£ëŠ” ì¤‘....\n",
      "ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤.....\n",
      "ì¸ì‹ëœ í…ìŠ¤íŠ¸: You\n",
      "ì±—ë´‡ ë‹µë³€: ë­, í•„ìš”í•œ ê±°ë¼ë„ ìˆë‚˜?\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ íŒŒì¼ì„ ì‚¬ìš© ì¤‘ì´ê¸° ë•Œë¬¸ì— í”„ë¡œì„¸ìŠ¤ê°€ ì•¡ì„¸ìŠ¤ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\tmpejh7c9kq.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m sound = AudioSegment.from_mp3(temp_path)\n\u001b[32m     37\u001b[39m play(sound)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPermissionError\u001b[39m: [WinError 32] ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ê°€ íŒŒì¼ì„ ì‚¬ìš© ì¤‘ì´ê¸° ë•Œë¬¸ì— í”„ë¡œì„¸ìŠ¤ê°€ ì•¡ì„¸ìŠ¤ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: 'C:\\\\Users\\\\user\\\\AppData\\\\Local\\\\Temp\\\\tmpejh7c9kq.mp3'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "while True:\n",
    "    r = sr.Recognizer() \n",
    "    # ì‹¤ìŠµ í•´ë³´ë©´ì„œ ë„£ì„ ìˆ˜ ìˆëŠ” ì˜µì…˜ êµ¬ê¸€ë§ í•´ë³´ê¸°.\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"ğŸ“¢ ë“£ëŠ” ì¤‘....\")\n",
    "        # STEP 1. ë§ˆì´í¬ë¡œë¶€í„° ì…ë ¥\n",
    "        r.adjust_for_ambient_noise(source) \n",
    "        audio = r.listen(source)         \n",
    "        print(\"ì¸ì‹ ì¤‘ì…ë‹ˆë‹¤.....\")\n",
    "\n",
    "        # STEP 2. Whisper APIë¥¼ í†µí•œ í…ìŠ¤íŠ¸ ë³€í™˜\n",
    "        user_text = r.recognize_openai(audio) \n",
    "        print(f\"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {user_text}\")\n",
    "\n",
    "        if user_text == \"ê·¸ë§Œ\":\n",
    "            break\n",
    "        \n",
    "        # STEP 3. ì¸ê³µì§€ëŠ¥ ì±—ë´‡ ì‘ë‹µ\n",
    "        answer = chat(user_text)\n",
    "        print(f\"ì±—ë´‡ ë‹µë³€: {answer}\")\n",
    "\n",
    "        # STEP 4. Whisper APIë¡œ ì‘ë‹µ\n",
    "        with client.audio.speech.with_streaming_response.create(\n",
    "            model=\"gpt-4o-mini-tts\",\n",
    "            voice=\"coral\",\n",
    "            input=answer,\n",
    "            instructions=\"ë°ì€ ëª©ì†Œë¦¬ë¡œ ë§í•´ì¤˜\"\n",
    "        ) as response:\n",
    "            # ìŒì„± í•©ì„± ê²°ê³¼ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_file:\n",
    "                temp_path = temp_file.name\n",
    "                response.stream_to_file(temp_path)\n",
    "\n",
    "                # ì¬ìƒ\n",
    "                sound = AudioSegment.from_mp3(temp_path)\n",
    "                play(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152716d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poten_up09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
