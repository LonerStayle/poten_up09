{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90a0aeb1",
   "metadata": {},
   "source": [
    "# 1. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa4053ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-10 2025-09-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10392\\4076130856.py:12: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>009450.KS</th>\n",
       "      <th>009450.KS</th>\n",
       "      <th>009450.KS</th>\n",
       "      <th>009450.KS</th>\n",
       "      <th>009450.KS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-10</th>\n",
       "      <td>57102.957031</td>\n",
       "      <td>58816.045742</td>\n",
       "      <td>55009.181940</td>\n",
       "      <td>55389.868320</td>\n",
       "      <td>384979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-11</th>\n",
       "      <td>57293.300781</td>\n",
       "      <td>58054.673549</td>\n",
       "      <td>55389.868862</td>\n",
       "      <td>56531.928013</td>\n",
       "      <td>153445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>55865.726562</td>\n",
       "      <td>57293.300495</td>\n",
       "      <td>55580.211776</td>\n",
       "      <td>57293.300495</td>\n",
       "      <td>125104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>56246.414062</td>\n",
       "      <td>56531.928855</td>\n",
       "      <td>54438.153712</td>\n",
       "      <td>55865.727673</td>\n",
       "      <td>107441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>55865.726562</td>\n",
       "      <td>58530.531237</td>\n",
       "      <td>54533.324225</td>\n",
       "      <td>56246.412945</td>\n",
       "      <td>234832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price              Close          High           Low          Open    Volume\n",
       "Ticker         009450.KS     009450.KS     009450.KS     009450.KS 009450.KS\n",
       "Date                                                                        \n",
       "2020-09-10  57102.957031  58816.045742  55009.181940  55389.868320    384979\n",
       "2020-09-11  57293.300781  58054.673549  55389.868862  56531.928013    153445\n",
       "2020-09-14  55865.726562  57293.300495  55580.211776  57293.300495    125104\n",
       "2020-09-15  56246.414062  56531.928855  54438.153712  55865.727673    107441\n",
       "2020-09-16  55865.726562  58530.531237  54533.324225  56246.412945    234832"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uv add yfinance \n",
    "import yfinance as yf \n",
    "from datetime import date, timedelta \n",
    "\n",
    "year = 5\n",
    "today = date.today()\n",
    "end_date = today.strftime(\"%Y-%m-%d\")\n",
    "start_date = today - timedelta(days=365*year)\n",
    "\n",
    "print(start_date, end_date)\n",
    "\n",
    "data = yf.download(\n",
    "    tickers = \"009450.KS\",\n",
    "    start = start_date,\n",
    "    end = end_date\n",
    ")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96ef9044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-10</th>\n",
       "      <td>57102.957031</td>\n",
       "      <td>58816.045742</td>\n",
       "      <td>55009.181940</td>\n",
       "      <td>55389.868320</td>\n",
       "      <td>384979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-11</th>\n",
       "      <td>57293.300781</td>\n",
       "      <td>58054.673549</td>\n",
       "      <td>55389.868862</td>\n",
       "      <td>56531.928013</td>\n",
       "      <td>153445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>55865.726562</td>\n",
       "      <td>57293.300495</td>\n",
       "      <td>55580.211776</td>\n",
       "      <td>57293.300495</td>\n",
       "      <td>125104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>56246.414062</td>\n",
       "      <td>56531.928855</td>\n",
       "      <td>54438.153712</td>\n",
       "      <td>55865.727673</td>\n",
       "      <td>107441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>55865.726562</td>\n",
       "      <td>58530.531237</td>\n",
       "      <td>54533.324225</td>\n",
       "      <td>56246.412945</td>\n",
       "      <td>234832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price              Close          High           Low          Open  Volume\n",
       "Date                                                                      \n",
       "2020-09-10  57102.957031  58816.045742  55009.181940  55389.868320  384979\n",
       "2020-09-11  57293.300781  58054.673549  55389.868862  56531.928013  153445\n",
       "2020-09-14  55865.726562  57293.300495  55580.211776  57293.300495  125104\n",
       "2020-09-15  56246.414062  56531.928855  54438.153712  55865.727673  107441\n",
       "2020-09-16  55865.726562  58530.531237  54533.324225  56246.412945  234832"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 멀티컬럼 제거하기 \n",
    "data.columns = data.columns.droplevel(1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb9b202f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-09-10</th>\n",
       "      <td>57102.957031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-11</th>\n",
       "      <td>57293.300781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-14</th>\n",
       "      <td>55865.726562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-15</th>\n",
       "      <td>56246.414062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-16</th>\n",
       "      <td>55865.726562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Price              Close\n",
       "Date                    \n",
       "2020-09-10  57102.957031\n",
       "2020-09-11  57293.300781\n",
       "2020-09-14  55865.726562\n",
       "2020-09-15  56246.414062\n",
       "2020-09-16  55865.726562"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\"Close\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ff7dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn pandas matplotlib \n",
    "# CUDA를 사용하기 위한 torch 설치 *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a54813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a65f10b",
   "metadata": {},
   "source": [
    "# 2. 데이터 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04e4dd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (857, 1), Val Data: (122, 1), Test Data: (244, 1)\n"
     ]
    }
   ],
   "source": [
    "N = len(data)\n",
    "test_ratio = 0.2 \n",
    "val_ratio = 0.1\n",
    "\n",
    "test_size = int(N * test_ratio)\n",
    "val_size = int(N * val_ratio)\n",
    "train_size = N - val_size - test_size\n",
    "\n",
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size:(train_size+val_size)]\n",
    "test_data = data.iloc[(train_size+val_size):]\n",
    "\n",
    "print(f\"Train Data: {train_data.shape}, Val Data: {val_data.shape}, Test Data: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c661ecfe",
   "metadata": {},
   "source": [
    "# 3. 데이터 스케일러 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31d39333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_scaled: float64\n",
      "val_scaled: float64\n",
      "test_scaled: float64\n",
      "Scale 범위: [32080.44335938], [74072.0234375]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# 질문1. MinMaxScaler는 무엇일까? \n",
    "# 질문2. 스케일러를 사용할 때 반드시 주의해야할 점은 무엇일까?\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_data.values)\n",
    "val_scaled = scaler.transform(val_data.values)\n",
    "test_scaled = scaler.transform(test_data.values)\n",
    "\n",
    "print(f\"train_scaled: {train_scaled.dtype}\")\n",
    "print(f\"val_scaled: {val_scaled.dtype}\")\n",
    "print(f\"test_scaled: {test_scaled.dtype}\")\n",
    "\n",
    "print(f\"Scale 범위: {scaler.data_min_}, {scaler.data_max_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61d81fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5958936 ],\n",
       "       [0.6004265 ],\n",
       "       [0.56642982],\n",
       "       [0.57549563],\n",
       "       [0.56642982],\n",
       "       [0.51430153],\n",
       "       [0.51656808],\n",
       "       [0.47577204],\n",
       "       [0.45764053],\n",
       "       [0.47350569],\n",
       "       [0.43724256],\n",
       "       [0.38058146],\n",
       "       [0.43950892],\n",
       "       [0.4304432 ],\n",
       "       [0.48483785],\n",
       "       [0.4916373 ],\n",
       "       [0.48483785],\n",
       "       [0.51203517],\n",
       "       [0.51883453],\n",
       "       [0.51883453],\n",
       "       [0.4871043 ],\n",
       "       [0.47803859],\n",
       "       [0.45764053],\n",
       "       [0.45990689],\n",
       "       [0.46670624],\n",
       "       [0.48937066],\n",
       "       [0.46670624],\n",
       "       [0.46443979],\n",
       "       [0.41457804],\n",
       "       [0.4213774 ],\n",
       "       [0.43950892],\n",
       "       [0.43724256],\n",
       "       [0.43724256],\n",
       "       [0.44404191],\n",
       "       [0.44404191],\n",
       "       [0.43270956],\n",
       "       [0.44177537],\n",
       "       [0.45990689],\n",
       "       [0.50070301],\n",
       "       [0.56642982],\n",
       "       [0.52790024],\n",
       "       [0.48937066],\n",
       "       [0.48937066],\n",
       "       [0.4871043 ],\n",
       "       [0.46670624],\n",
       "       [0.46897269],\n",
       "       [0.4871043 ],\n",
       "       [0.4871043 ],\n",
       "       [0.47803859],\n",
       "       [0.49390375],\n",
       "       [0.49843656],\n",
       "       [0.46897269],\n",
       "       [0.45310772],\n",
       "       [0.44177537],\n",
       "       [0.44857481],\n",
       "       [0.44630836],\n",
       "       [0.44404191],\n",
       "       [0.42364385],\n",
       "       [0.41457804],\n",
       "       [0.4259103 ],\n",
       "       [0.43724256],\n",
       "       [0.46217334],\n",
       "       [0.44630836],\n",
       "       [0.43270956],\n",
       "       [0.4259103 ],\n",
       "       [0.43270956],\n",
       "       [0.41911095],\n",
       "       [0.43950892],\n",
       "       [0.43950892],\n",
       "       [0.41457804],\n",
       "       [0.41457804],\n",
       "       [0.41457804],\n",
       "       [0.40097934],\n",
       "       [0.42494024],\n",
       "       [0.42494024],\n",
       "       [0.41353031],\n",
       "       [0.42950421],\n",
       "       [0.42722223],\n",
       "       [0.44776001],\n",
       "       [0.450042  ],\n",
       "       [0.44319613],\n",
       "       [0.43635017],\n",
       "       [0.42950421],\n",
       "       [0.42037627],\n",
       "       [0.41581239],\n",
       "       [0.37587748],\n",
       "       [0.38842855],\n",
       "       [0.39527451],\n",
       "       [0.39527451],\n",
       "       [0.3793006 ],\n",
       "       [0.3975564 ],\n",
       "       [0.38614656],\n",
       "       [0.3633266 ],\n",
       "       [0.3530578 ],\n",
       "       [0.33480182],\n",
       "       [0.34164787],\n",
       "       [0.35648064],\n",
       "       [0.34278882],\n",
       "       [0.33936589],\n",
       "       [0.34050693],\n",
       "       [0.33822485],\n",
       "       [0.34849383],\n",
       "       [0.35648064],\n",
       "       [0.3975564 ],\n",
       "       [0.40440236],\n",
       "       [0.41124832],\n",
       "       [0.43406819],\n",
       "       [0.44091405],\n",
       "       [0.42722223],\n",
       "       [0.42494024],\n",
       "       [0.39299234],\n",
       "       [0.39299234],\n",
       "       [0.39071054],\n",
       "       [0.38842855],\n",
       "       [0.39983848],\n",
       "       [0.3815825 ],\n",
       "       [0.37017266],\n",
       "       [0.3633266 ],\n",
       "       [0.3553397 ],\n",
       "       [0.3530578 ],\n",
       "       [0.3633266 ],\n",
       "       [0.39071054],\n",
       "       [0.38386458],\n",
       "       [0.41124832],\n",
       "       [0.40896633],\n",
       "       [0.40896633],\n",
       "       [0.40668435],\n",
       "       [0.40896633],\n",
       "       [0.39299234],\n",
       "       [0.39983848],\n",
       "       [0.40668435],\n",
       "       [0.39983848],\n",
       "       [0.3975564 ],\n",
       "       [0.39983848],\n",
       "       [0.3975564 ],\n",
       "       [0.40440236],\n",
       "       [0.38842855],\n",
       "       [0.3815825 ],\n",
       "       [0.38386458],\n",
       "       [0.3713137 ],\n",
       "       [0.3713137 ],\n",
       "       [0.3975564 ],\n",
       "       [0.40896633],\n",
       "       [0.42037627],\n",
       "       [0.42722223],\n",
       "       [0.4317862 ],\n",
       "       [0.43863216],\n",
       "       [0.48883568],\n",
       "       [0.48655388],\n",
       "       [0.55957726],\n",
       "       [0.55501328],\n",
       "       [0.54132146],\n",
       "       [0.54816742],\n",
       "       [0.52306547],\n",
       "       [0.49568173],\n",
       "       [0.48655388],\n",
       "       [0.49568173],\n",
       "       [0.50024579],\n",
       "       [0.53903947],\n",
       "       [0.53903947],\n",
       "       [0.57783324],\n",
       "       [0.57326918],\n",
       "       [0.68280443],\n",
       "       [0.65998457],\n",
       "       [0.62575477],\n",
       "       [0.71475215],\n",
       "       [0.67824037],\n",
       "       [0.71018818],\n",
       "       [0.69193229],\n",
       "       [0.66911242],\n",
       "       [0.68736831],\n",
       "       [0.75126384],\n",
       "       [0.739854  ],\n",
       "       [0.76723784],\n",
       "       [0.71247017],\n",
       "       [0.66683053],\n",
       "       [0.6713945 ],\n",
       "       [0.69193229],\n",
       "       [0.65998457],\n",
       "       [0.70106023],\n",
       "       [0.69649626],\n",
       "       [0.69649626],\n",
       "       [0.7238801 ],\n",
       "       [0.71475215],\n",
       "       [0.73300804],\n",
       "       [0.73757211],\n",
       "       [0.78549364],\n",
       "       [0.77408389],\n",
       "       [0.76723784],\n",
       "       [0.82885111],\n",
       "       [0.80374953],\n",
       "       [0.85851721],\n",
       "       [0.87449121],\n",
       "       [0.84710718],\n",
       "       [0.81972335],\n",
       "       [0.81287748],\n",
       "       [0.82656921],\n",
       "       [0.83569734],\n",
       "       [0.83797942],\n",
       "       [0.81515937],\n",
       "       [0.75582791],\n",
       "       [0.74669987],\n",
       "       [0.71931622],\n",
       "       [0.739854  ],\n",
       "       [0.70562421],\n",
       "       [0.76951964],\n",
       "       [0.79005761],\n",
       "       [0.79690348],\n",
       "       [0.78321165],\n",
       "       [0.78777572],\n",
       "       [0.79918575],\n",
       "       [0.76951964],\n",
       "       [0.82885111],\n",
       "       [0.81744145],\n",
       "       [0.8242875 ],\n",
       "       [0.79690348],\n",
       "       [0.7763657 ],\n",
       "       [0.86308118],\n",
       "       [0.92241265],\n",
       "       [0.91556678],\n",
       "       [0.90872073],\n",
       "       [0.88818294],\n",
       "       [0.93838646],\n",
       "       [0.9475144 ],\n",
       "       [0.99771829],\n",
       "       [1.        ],\n",
       "       [0.99771829],\n",
       "       [0.90187486],\n",
       "       [0.92469454],\n",
       "       [0.90872073],\n",
       "       [0.85623532],\n",
       "       [0.8448251 ],\n",
       "       [0.78321165],\n",
       "       [0.73072597],\n",
       "       [0.7581099 ],\n",
       "       [0.78092976],\n",
       "       [0.78092976],\n",
       "       [0.77408389],\n",
       "       [0.76495586],\n",
       "       [0.75354583],\n",
       "       [0.76951964],\n",
       "       [0.75582791],\n",
       "       [0.78777572],\n",
       "       [0.81972335],\n",
       "       [0.80146745],\n",
       "       [0.80603161],\n",
       "       [0.80374953],\n",
       "       [0.7763657 ],\n",
       "       [0.75126384],\n",
       "       [0.73072597],\n",
       "       [0.73072597],\n",
       "       [0.73528994],\n",
       "       [0.75354583],\n",
       "       [0.71931622],\n",
       "       [0.70334222],\n",
       "       [0.68508633],\n",
       "       [0.69649626],\n",
       "       [0.68280443],\n",
       "       [0.62575477],\n",
       "       [0.61206295],\n",
       "       [0.56642322],\n",
       "       [0.56642322],\n",
       "       [0.52762954],\n",
       "       [0.59837103],\n",
       "       [0.59837103],\n",
       "       [0.58467911],\n",
       "       [0.602935  ],\n",
       "       [0.63716471],\n",
       "       [0.72844416],\n",
       "       [0.76723784],\n",
       "       [0.77180182],\n",
       "       [0.76723784],\n",
       "       [0.73072597],\n",
       "       [0.75126384],\n",
       "       [0.739854  ],\n",
       "       [0.75354583],\n",
       "       [0.74898195],\n",
       "       [0.7421359 ],\n",
       "       [0.76495586],\n",
       "       [0.7763657 ],\n",
       "       [0.7763657 ],\n",
       "       [0.79005761],\n",
       "       [0.8105954 ],\n",
       "       [0.8105954 ],\n",
       "       [0.81744145],\n",
       "       [0.66683053],\n",
       "       [0.67367649],\n",
       "       [0.67367649],\n",
       "       [0.66226656],\n",
       "       [0.6394466 ],\n",
       "       [0.59837103],\n",
       "       [0.58239712],\n",
       "       [0.56642322],\n",
       "       [0.5869611 ],\n",
       "       [0.56642322],\n",
       "       [0.58239712],\n",
       "       [0.61206295],\n",
       "       [0.59152498],\n",
       "       [0.5527313 ],\n",
       "       [0.5185015 ],\n",
       "       [0.4317862 ],\n",
       "       [0.45688805],\n",
       "       [0.50024579],\n",
       "       [0.52078358],\n",
       "       [0.50252778],\n",
       "       [0.5185015 ],\n",
       "       [0.50480967],\n",
       "       [0.50252778],\n",
       "       [0.50709166],\n",
       "       [0.48883568],\n",
       "       [0.47514385],\n",
       "       [0.45460606],\n",
       "       [0.46829789],\n",
       "       [0.46145212],\n",
       "       [0.44547812],\n",
       "       [0.44319613],\n",
       "       [0.450042  ],\n",
       "       [0.44547812],\n",
       "       [0.44776001],\n",
       "       [0.47057988],\n",
       "       [0.47057988],\n",
       "       [0.480935  ],\n",
       "       [0.49934392],\n",
       "       [0.49474171],\n",
       "       [0.52465629],\n",
       "       [0.49013942],\n",
       "       [0.51315082],\n",
       "       [0.49934392],\n",
       "       [0.48323606],\n",
       "       [0.49934392],\n",
       "       [0.49934392],\n",
       "       [0.49934392],\n",
       "       [0.46712829],\n",
       "       [0.43261142],\n",
       "       [0.43721363],\n",
       "       [0.43951478],\n",
       "       [0.39809455],\n",
       "       [0.35667423],\n",
       "       [0.31180232],\n",
       "       [0.31180232],\n",
       "       [0.27383377],\n",
       "       [0.34977097],\n",
       "       [0.42340692],\n",
       "       [0.43031027],\n",
       "       [0.42110577],\n",
       "       [0.42110577],\n",
       "       [0.42110577],\n",
       "       [0.40269666],\n",
       "       [0.38543827],\n",
       "       [0.34171708],\n",
       "       [0.32560913],\n",
       "       [0.33711478],\n",
       "       [0.33711478],\n",
       "       [0.31755515],\n",
       "       [0.31755515],\n",
       "       [0.31755515],\n",
       "       [0.31755515],\n",
       "       [0.25657529],\n",
       "       [0.26117759],\n",
       "       [0.26117759],\n",
       "       [0.2393169 ],\n",
       "       [0.27843607],\n",
       "       [0.27843607],\n",
       "       [0.25772601],\n",
       "       [0.24161815],\n",
       "       [0.24161815],\n",
       "       [0.24161815],\n",
       "       [0.23126302],\n",
       "       [0.23126302],\n",
       "       [0.23126302],\n",
       "       [0.23126302],\n",
       "       [0.26693051],\n",
       "       [0.26693051],\n",
       "       [0.27843607],\n",
       "       [0.29684508],\n",
       "       [0.31410347],\n",
       "       [0.32330798],\n",
       "       [0.30720003],\n",
       "       [0.29224279],\n",
       "       [0.29224279],\n",
       "       [0.29684508],\n",
       "       [0.34056637],\n",
       "       [0.37623386],\n",
       "       [0.4003957 ],\n",
       "       [0.4049979 ],\n",
       "       [0.36472821],\n",
       "       [0.37048113],\n",
       "       [0.3819866 ],\n",
       "       [0.37738439],\n",
       "       [0.36357758],\n",
       "       [0.3555237 ],\n",
       "       [0.36127653],\n",
       "       [0.39349234],\n",
       "       [0.39809455],\n",
       "       [0.41650347],\n",
       "       [0.41880462],\n",
       "       [0.42570806],\n",
       "       [0.4049979 ],\n",
       "       [0.41650347],\n",
       "       [0.40729896],\n",
       "       [0.41650347],\n",
       "       [0.41880462],\n",
       "       [0.44181593],\n",
       "       [0.44871928],\n",
       "       [0.43261142],\n",
       "       [0.41650347],\n",
       "       [0.35437327],\n",
       "       [0.33596416],\n",
       "       [0.30835065],\n",
       "       [0.31295295],\n",
       "       [0.33826531],\n",
       "       [0.37278209],\n",
       "       [0.37508333],\n",
       "       [0.34862035],\n",
       "       [0.33366301],\n",
       "       [0.32675966],\n",
       "       [0.30835065],\n",
       "       [0.29569456],\n",
       "       [0.2749844 ],\n",
       "       [0.27613492],\n",
       "       [0.29109226],\n",
       "       [0.29224279],\n",
       "       [0.28879111],\n",
       "       [0.29454384],\n",
       "       [0.27383377],\n",
       "       [0.26347883],\n",
       "       [0.25887654],\n",
       "       [0.25772601],\n",
       "       [0.22435976],\n",
       "       [0.20480013],\n",
       "       [0.17948776],\n",
       "       [0.16453033],\n",
       "       [0.15532583],\n",
       "       [0.1231102 ],\n",
       "       [0.14151921],\n",
       "       [0.12426082],\n",
       "       [0.09894836],\n",
       "       [0.15302486],\n",
       "       [0.17028325],\n",
       "       [0.17718652],\n",
       "       [0.16568095],\n",
       "       [0.1633799 ],\n",
       "       [0.13116408],\n",
       "       [0.11505632],\n",
       "       [0.1277125 ],\n",
       "       [0.12195958],\n",
       "       [0.12656178],\n",
       "       [0.12080905],\n",
       "       [0.11505632],\n",
       "       [0.1139056 ],\n",
       "       [0.11160454],\n",
       "       [0.1093034 ],\n",
       "       [0.10585172],\n",
       "       [0.13576638],\n",
       "       [0.12656178],\n",
       "       [0.15072362],\n",
       "       [0.16107875],\n",
       "       [0.15417539],\n",
       "       [0.15187415],\n",
       "       [0.14497089],\n",
       "       [0.14382027],\n",
       "       [0.14957309],\n",
       "       [0.15417539],\n",
       "       [0.15532583],\n",
       "       [0.15532583],\n",
       "       [0.16568095],\n",
       "       [0.14497089],\n",
       "       [0.14957309],\n",
       "       [0.16222928],\n",
       "       [0.14382027],\n",
       "       [0.12080905],\n",
       "       [0.14497089],\n",
       "       [0.12656178],\n",
       "       [0.14382027],\n",
       "       [0.15187415],\n",
       "       [0.14842257],\n",
       "       [0.14727194],\n",
       "       [0.12886303],\n",
       "       [0.11735737],\n",
       "       [0.12541126],\n",
       "       [0.14266965],\n",
       "       [0.136917  ],\n",
       "       [0.1323147 ],\n",
       "       [0.17258431],\n",
       "       [0.23356408],\n",
       "       [0.20249898],\n",
       "       [0.1587776 ],\n",
       "       [0.13001346],\n",
       "       [0.15187415],\n",
       "       [0.15187415],\n",
       "       [0.16222928],\n",
       "       [0.1679821 ],\n",
       "       [0.14957309],\n",
       "       [0.1679821 ],\n",
       "       [0.18408997],\n",
       "       [0.1898427 ],\n",
       "       [0.22090789],\n",
       "       [0.18408997],\n",
       "       [0.17488546],\n",
       "       [0.14727194],\n",
       "       [0.10124951],\n",
       "       [0.0828405 ],\n",
       "       [0.0379685 ],\n",
       "       [0.02761356],\n",
       "       [0.02301126],\n",
       "       [0.03566745],\n",
       "       [0.01610786],\n",
       "       [0.02301126],\n",
       "       [0.02416188],\n",
       "       [0.0069034 ],\n",
       "       [0.01380671],\n",
       "       [0.        ],\n",
       "       [0.00805398],\n",
       "       [0.00805398],\n",
       "       [0.02416188],\n",
       "       [0.01725844],\n",
       "       [0.01495738],\n",
       "       [0.00345172],\n",
       "       [0.02186064],\n",
       "       [0.02071011],\n",
       "       [0.02531232],\n",
       "       [0.03221577],\n",
       "       [0.02301126],\n",
       "       [0.02876409],\n",
       "       [0.03566745],\n",
       "       [0.02761356],\n",
       "       [0.01495738],\n",
       "       [0.01265618],\n",
       "       [0.01725844],\n",
       "       [0.02646294],\n",
       "       [0.0333663 ],\n",
       "       [0.02531232],\n",
       "       [0.03566745],\n",
       "       [0.05752813],\n",
       "       [0.06328096],\n",
       "       [0.05407646],\n",
       "       [0.03566745],\n",
       "       [0.03911903],\n",
       "       [0.01610786],\n",
       "       [0.01840906],\n",
       "       [0.01955959],\n",
       "       [0.02416188],\n",
       "       [0.02876409],\n",
       "       [0.02991462],\n",
       "       [0.04487195],\n",
       "       [0.07823829],\n",
       "       [0.07133485],\n",
       "       [0.06558211],\n",
       "       [0.06673264],\n",
       "       [0.06213043],\n",
       "       [0.05982919],\n",
       "       [0.03566745],\n",
       "       [0.03911903],\n",
       "       [0.04142027],\n",
       "       [0.05982919],\n",
       "       [0.05867866],\n",
       "       [0.05522689],\n",
       "       [0.04947425],\n",
       "       [0.05752813],\n",
       "       [0.03911903],\n",
       "       [0.04026975],\n",
       "       [0.04832363],\n",
       "       [0.02761356],\n",
       "       [0.02991462],\n",
       "       [0.02991462],\n",
       "       [0.03224963],\n",
       "       [0.02524469],\n",
       "       [0.00889994],\n",
       "       [0.00539752],\n",
       "       [0.01123491],\n",
       "       [0.00773248],\n",
       "       [0.00539752],\n",
       "       [0.00539752],\n",
       "       [0.01473738],\n",
       "       [0.01473738],\n",
       "       [0.02290977],\n",
       "       [0.0275797 ],\n",
       "       [0.02057476],\n",
       "       [0.0194073 ],\n",
       "       [0.01123491],\n",
       "       [0.00306251],\n",
       "       [0.00539752],\n",
       "       [0.02290977],\n",
       "       [0.03691946],\n",
       "       [0.04158939],\n",
       "       [0.05326426],\n",
       "       [0.05326426],\n",
       "       [0.05793419],\n",
       "       [0.05326426],\n",
       "       [0.05559927],\n",
       "       [0.05676673],\n",
       "       [0.04509186],\n",
       "       [0.04859433],\n",
       "       [0.04742687],\n",
       "       [0.04625932],\n",
       "       [0.04742687],\n",
       "       [0.06377167],\n",
       "       [0.06960905],\n",
       "       [0.08595385],\n",
       "       [0.1093034 ],\n",
       "       [0.13265313],\n",
       "       [0.12915066],\n",
       "       [0.11864325],\n",
       "       [0.11514087],\n",
       "       [0.09179114],\n",
       "       [0.0929586 ],\n",
       "       [0.11747579],\n",
       "       [0.13498805],\n",
       "       [0.13965788],\n",
       "       [0.13732306],\n",
       "       [0.13265313],\n",
       "       [0.1198108 ],\n",
       "       [0.10346601],\n",
       "       [0.08595385],\n",
       "       [0.07194397],\n",
       "       [0.03691946],\n",
       "       [0.04158939],\n",
       "       [0.02524469],\n",
       "       [0.03925447],\n",
       "       [0.03808692],\n",
       "       [0.04509186],\n",
       "       [0.02874716],\n",
       "       [0.03108217],\n",
       "       [0.02874716],\n",
       "       [0.01823985],\n",
       "       [0.02407723],\n",
       "       [0.03925447],\n",
       "       [0.03458464],\n",
       "       [0.0275797 ],\n",
       "       [0.05559927],\n",
       "       [0.08361884],\n",
       "       [0.08712131],\n",
       "       [0.07427898],\n",
       "       [0.07194397],\n",
       "       [0.05326426],\n",
       "       [0.06960905],\n",
       "       [0.05910165],\n",
       "       [0.06727404],\n",
       "       [0.07194397],\n",
       "       [0.06260411],\n",
       "       [0.07077651],\n",
       "       [0.06260411],\n",
       "       [0.04625932],\n",
       "       [0.05443172],\n",
       "       [0.06844159],\n",
       "       [0.0602692 ],\n",
       "       [0.17118001],\n",
       "       [0.2015345 ],\n",
       "       [0.17001246],\n",
       "       [0.23889401],\n",
       "       [0.22721915],\n",
       "       [0.25757363],\n",
       "       [0.19803203],\n",
       "       [0.21204181],\n",
       "       [0.21904675],\n",
       "       [0.21904675],\n",
       "       [0.1933621 ],\n",
       "       [0.20036704],\n",
       "       [0.17234747],\n",
       "       [0.20036704],\n",
       "       [0.20036704],\n",
       "       [0.20270196],\n",
       "       [0.21554428],\n",
       "       [0.21087435],\n",
       "       [0.22605169],\n",
       "       [0.22488414],\n",
       "       [0.21904675],\n",
       "       [0.19569711],\n",
       "       [0.1933621 ],\n",
       "       [0.16300761],\n",
       "       [0.17935241],\n",
       "       [0.18985972],\n",
       "       [0.1770174 ],\n",
       "       [0.19102709],\n",
       "       [0.2015345 ],\n",
       "       [0.20737188],\n",
       "       [0.22138176],\n",
       "       [0.27858836],\n",
       "       [0.26808104],\n",
       "       [0.24823378],\n",
       "       [0.24589877],\n",
       "       [0.2529037 ],\n",
       "       [0.29376569],\n",
       "       [0.41284881],\n",
       "       [0.3941691 ],\n",
       "       [0.38949917],\n",
       "       [0.38949917],\n",
       "       [0.4105138 ],\n",
       "       [0.38482924],\n",
       "       [0.42218867],\n",
       "       [0.49690751],\n",
       "       [0.48756766],\n",
       "       [0.47355787],\n",
       "       [0.46421802],\n",
       "       [0.46655293],\n",
       "       [0.43152852],\n",
       "       [0.48056272],\n",
       "       [0.50391236],\n",
       "       [0.45254315],\n",
       "       [0.45487807],\n",
       "       [0.44086838],\n",
       "       [0.42452358],\n",
       "       [0.42919351],\n",
       "       [0.44553831],\n",
       "       [0.49690751],\n",
       "       [0.50858229],\n",
       "       [0.60198094],\n",
       "       [0.46421802],\n",
       "       [0.54360679],\n",
       "       [0.57396128],\n",
       "       [0.59030607],\n",
       "       [0.59264108],\n",
       "       [0.60431586],\n",
       "       [0.60665078],\n",
       "       [0.57396128],\n",
       "       [0.55528157],\n",
       "       [0.5786313 ],\n",
       "       [0.59030607],\n",
       "       [0.54360679],\n",
       "       [0.57629629],\n",
       "       [0.62533049],\n",
       "       [0.37315437],\n",
       "       [0.39183418],\n",
       "       [0.44320339],\n",
       "       [0.44787332],\n",
       "       [0.45020814],\n",
       "       [0.40817879],\n",
       "       [0.39183418],\n",
       "       [0.3778243 ],\n",
       "       [0.40817879],\n",
       "       [0.43386344],\n",
       "       [0.44553831],\n",
       "       [0.46188301],\n",
       "       [0.40350886],\n",
       "       [0.36614953],\n",
       "       [0.40350886],\n",
       "       [0.36614953],\n",
       "       [0.33812996],\n",
       "       [0.34980473],\n",
       "       [0.34279989],\n",
       "       [0.32995756],\n",
       "       [0.33929742],\n",
       "       [0.35447466],\n",
       "       [0.35914459],\n",
       "       [0.31127785],\n",
       "       [0.3019379 ],\n",
       "       [0.29726797],\n",
       "       [0.26574603],\n",
       "       [0.25173625],\n",
       "       [0.25757363],\n",
       "       [0.23072162],\n",
       "       [0.25173625],\n",
       "       [0.20036704],\n",
       "       [0.26341102],\n",
       "       [0.32762265],\n",
       "       [0.30660792],\n",
       "       [0.35213965],\n",
       "       [0.33346003],\n",
       "       [0.33579495],\n",
       "       [0.36381452],\n",
       "       [0.39650411],\n",
       "       [0.37081946],\n",
       "       [0.31945025],\n",
       "       [0.32178517],\n",
       "       [0.30310545],\n",
       "       [0.33346003],\n",
       "       [0.31945025],\n",
       "       [0.28559329],\n",
       "       [0.32528764],\n",
       "       [0.35564212],\n",
       "       [0.35447466],\n",
       "       [0.36848445],\n",
       "       [0.37899185],\n",
       "       [0.39066663],\n",
       "       [0.36848445],\n",
       "       [0.36965191],\n",
       "       [0.43853346],\n",
       "       [0.40817879],\n",
       "       [0.4105138 ],\n",
       "       [0.36381452],\n",
       "       [0.37899185],\n",
       "       [0.37899185],\n",
       "       [0.37899185],\n",
       "       [0.37432183],\n",
       "       [0.36381452],\n",
       "       [0.36264706],\n",
       "       [0.35447466],\n",
       "       [0.34630227],\n",
       "       [0.35097219],\n",
       "       [0.34746972],\n",
       "       [0.37081946],\n",
       "       [0.33812996],\n",
       "       [0.3019379 ],\n",
       "       [0.3101103 ],\n",
       "       [0.29493306],\n",
       "       [0.28209082],\n",
       "       [0.28909567],\n",
       "       [0.32762265],\n",
       "       [0.33346003],\n",
       "       [0.34396735],\n",
       "       [0.3019379 ],\n",
       "       [0.28792821],\n",
       "       [0.2610761 ],\n",
       "       [0.29259814],\n",
       "       [0.29610052],\n",
       "       [0.3019379 ],\n",
       "       [0.28559329],\n",
       "       [0.29259814],\n",
       "       [0.32061771],\n",
       "       [0.29843553],\n",
       "       [0.33507038],\n",
       "       [0.35161509],\n",
       "       [0.29134501],\n",
       "       [0.26770959],\n",
       "       [0.28189082],\n",
       "       [0.27480021],\n",
       "       [0.27361842],\n",
       "       [0.29016322],\n",
       "       [0.31143497],\n",
       "       [0.34334269],\n",
       "       [0.3338886 ],\n",
       "       [0.36934158],\n",
       "       [0.37879576],\n",
       "       [0.35516044],\n",
       "       [0.34097921],\n",
       "       [0.34097921],\n",
       "       [0.40597643],\n",
       "       [0.3917952 ],\n",
       "       [0.38470459],\n",
       "       [0.36461453],\n",
       "       [0.34806983],\n",
       "       [0.40833991],\n",
       "       [0.37643219],\n",
       "       [0.34688804],\n",
       "       [0.38588637],\n",
       "       [0.40361286],\n",
       "       [0.3917952 ],\n",
       "       [0.36225096],\n",
       "       [0.38706816],\n",
       "       [0.40124929],\n",
       "       [0.41424874],\n",
       "       [0.43670236],\n",
       "       [0.43433879],\n",
       "       [0.44379298],\n",
       "       [0.45088359],\n",
       "       [0.50760841],\n",
       "       [0.48870014],\n",
       "       [0.56669671],\n",
       "       [0.56669671],\n",
       "       [0.53597078],\n",
       "       [0.5170625 ],\n",
       "       [0.50997189],\n",
       "       [0.48870014],\n",
       "       [0.55960609],\n",
       "       [0.54069782],\n",
       "       [0.50288127],\n",
       "       [0.5170625 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5a689",
   "metadata": {},
   "source": [
    "# 4. 학습 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba157538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data: (857, 1), Val Data: (122, 1), Test Data: (244, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Data: {train_scaled.shape}, Val Data: {val_scaled.shape}, Test Data: {test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7a218b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857, 1)\n"
     ]
    }
   ],
   "source": [
    "print(train_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe9f8d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 7\n",
      "1 8\n",
      "2 9\n",
      "3 10\n",
      "4 11\n",
      "5 12\n",
      "6 13\n"
     ]
    }
   ],
   "source": [
    "# 데이터 움직이는 패턴 파악하기\n",
    "window = 7\n",
    "for i in range(0, 14 - window): # 14 - 7 = 7\n",
    "    print(i, i + window)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0e86d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5005178]\n",
      "[0.5005178]\n"
     ]
    }
   ],
   "source": [
    "print(val_scaled[0])\n",
    "print(val_scaled[0, [-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9e0c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "test_data = np.array([[1.0, 2.0]])\n",
    "print(test_data[0])\n",
    "print(test_data[0, [-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d520e362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Data: (857, 1), Val Data: (122, 1), Test Data: (244, 1)\n",
    "len(np.concatenate([train_scaled[-window:], val_scaled]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cff8f33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(857, 1) (797, 60, 1) (797, 1)\n",
      "(122, 1) (122, 60, 1) (122, 1)\n",
      "(244, 1) (244, 60, 1) (244, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# 질문 1. Window가 무엇을 의미하는지 설명할 수 있다. \n",
    "# 질문 2. train data가 몇 개 나오는지 설명할 수 있다. \n",
    "def make_dataset(data, window):\n",
    "    dataX = []\n",
    "    datay = []\n",
    "\n",
    "    for i in range(0, data.shape[0] - window):\n",
    "        # print(i,i+window)\n",
    "        x = data[i:(i+window), :]\n",
    "        y = data[(i+window), [-1]]\n",
    "\n",
    "        dataX.append(x)\n",
    "        datay.append(y)\n",
    "    # print(\"==============\")\n",
    "    return np.array(dataX), np.array(datay)\n",
    "\n",
    "window = 60\n",
    "\n",
    "X_train, y_train = make_dataset(train_scaled, window=window)\n",
    "# val_scaled의 X, y를 만들기 위해서는 train_scaled에서 맨 뒤에서 window만큼 가져와야 한다. \n",
    "X_val, y_val = make_dataset(np.concatenate([train_scaled[-window:], val_scaled]), window=window)\n",
    "X_test, y_test = make_dataset(np.concatenate([val_scaled[-window:], test_scaled]), window=window)\n",
    "\n",
    "print(train_scaled.shape, X_train.shape, y_train.shape)\n",
    "print(val_scaled.shape, X_val.shape, y_val.shape)\n",
    "print(test_scaled.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48c49a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4556031d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2]\n",
      " [ 3  4]\n",
      " [ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "b = np.array([[7, 8], [9, 10], [11, 12]])\n",
    "\n",
    "print(np.concatenate((a, b), axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5848ee4",
   "metadata": {},
   "source": [
    "# 5. DataLoader 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f227c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "X_train_ts = torch.FloatTensor(X_train)\n",
    "y_train_ts = torch.FloatTensor(y_train)\n",
    "X_val_ts = torch.FloatTensor(X_val)\n",
    "y_val_ts = torch.FloatTensor(y_val)\n",
    "X_test_ts = torch.FloatTensor(X_test)\n",
    "y_test_ts = torch.FloatTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6353e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "797\n",
      "122\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader \n",
    "\n",
    "train_dataset = TensorDataset(X_train_ts, y_train_ts)\n",
    "print(len(train_dataset))\n",
    "# print(train_dataset[0])\n",
    "\n",
    "val_dataset = TensorDataset(X_val_ts, y_val_ts)\n",
    "print(len(val_dataset))\n",
    "# print(val_dataset[0])\n",
    "\n",
    "test_dataset = TensorDataset(X_test_ts, y_test_ts)\n",
    "print(len(test_dataset))\n",
    "# print(test_dataset[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fa6c15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 질문1. DataLoader가 뭔가요?\n",
    "batch_size = 50\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055a1b52",
   "metadata": {},
   "source": [
    "# 5. 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c2887f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "\n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self,input_size, hidden_size, num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_size,\n",
    "            num_layers = num_layers,\n",
    "            batch_first = True,\n",
    "            dropout = dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # out : 모든 시점의 hidden \n",
    "        # hn : \"마지막 시점\"의 요약 정보\n",
    "        # cn : 마지막 시적의 셀 상태 \n",
    "        out, (hn,cn) = self.lstm(x)\n",
    "        pred = self.fc(hn[-1])\n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41fe9337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMRegressor(\n",
       "  (lstm): LSTM(1, 128, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 만들기\n",
    "model = LSTMRegressor(input_size=1, hidden_size=128, num_layers=2, dropout=0.2)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf78ca4",
   "metadata": {},
   "source": [
    "# 6. 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b9cd2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정의\n",
    "lr  = 1e-5\n",
    "criterion = nn.MSELoss() # 손실함수\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr) # 최적화 함수\n",
    "epochs = 100 # epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a22f444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, train_loss=0.1454, val_loss=0.3181\n",
      "Epoch: 1, train_loss=0.1423, val_loss=0.3127\n",
      "Epoch: 2, train_loss=0.1393, val_loss=0.3073\n",
      "Epoch: 3, train_loss=0.1365, val_loss=0.3019\n",
      "Epoch: 4, train_loss=0.1336, val_loss=0.2967\n",
      "Epoch: 5, train_loss=0.1309, val_loss=0.2915\n",
      "Epoch: 6, train_loss=0.1281, val_loss=0.2863\n",
      "Epoch: 7, train_loss=0.1255, val_loss=0.2812\n",
      "Epoch: 8, train_loss=0.1228, val_loss=0.2762\n",
      "Epoch: 9, train_loss=0.1203, val_loss=0.2711\n",
      "Epoch: 10, train_loss=0.1176, val_loss=0.2661\n",
      "Epoch: 11, train_loss=0.1151, val_loss=0.2611\n",
      "Epoch: 12, train_loss=0.1125, val_loss=0.2561\n",
      "Epoch: 13, train_loss=0.1100, val_loss=0.2510\n",
      "Epoch: 14, train_loss=0.1076, val_loss=0.2460\n",
      "Epoch: 15, train_loss=0.1051, val_loss=0.2409\n",
      "Epoch: 16, train_loss=0.1027, val_loss=0.2358\n",
      "Epoch: 17, train_loss=0.1004, val_loss=0.2307\n",
      "Epoch: 18, train_loss=0.0980, val_loss=0.2255\n",
      "Epoch: 19, train_loss=0.0955, val_loss=0.2203\n",
      "Epoch: 20, train_loss=0.0932, val_loss=0.2151\n",
      "Epoch: 21, train_loss=0.0908, val_loss=0.2097\n",
      "Epoch: 22, train_loss=0.0885, val_loss=0.2044\n",
      "Epoch: 23, train_loss=0.0861, val_loss=0.1990\n",
      "Epoch: 24, train_loss=0.0837, val_loss=0.1935\n",
      "Epoch: 25, train_loss=0.0816, val_loss=0.1881\n",
      "Epoch: 26, train_loss=0.0793, val_loss=0.1825\n",
      "Epoch: 27, train_loss=0.0771, val_loss=0.1770\n",
      "Epoch: 28, train_loss=0.0749, val_loss=0.1714\n",
      "Epoch: 29, train_loss=0.0728, val_loss=0.1659\n",
      "Epoch: 30, train_loss=0.0706, val_loss=0.1604\n",
      "Epoch: 31, train_loss=0.0685, val_loss=0.1548\n",
      "Epoch: 32, train_loss=0.0667, val_loss=0.1494\n",
      "Epoch: 33, train_loss=0.0647, val_loss=0.1440\n",
      "Epoch: 34, train_loss=0.0631, val_loss=0.1387\n",
      "Epoch: 35, train_loss=0.0611, val_loss=0.1335\n",
      "Epoch: 36, train_loss=0.0598, val_loss=0.1285\n",
      "Epoch: 37, train_loss=0.0581, val_loss=0.1236\n",
      "Epoch: 38, train_loss=0.0568, val_loss=0.1188\n",
      "Epoch: 39, train_loss=0.0555, val_loss=0.1143\n",
      "Epoch: 40, train_loss=0.0544, val_loss=0.1101\n",
      "Epoch: 41, train_loss=0.0533, val_loss=0.1060\n",
      "Epoch: 42, train_loss=0.0523, val_loss=0.1022\n",
      "Epoch: 43, train_loss=0.0515, val_loss=0.0986\n",
      "Epoch: 44, train_loss=0.0507, val_loss=0.0953\n",
      "Epoch: 45, train_loss=0.0500, val_loss=0.0922\n",
      "Epoch: 46, train_loss=0.0493, val_loss=0.0893\n",
      "Epoch: 47, train_loss=0.0486, val_loss=0.0867\n",
      "Epoch: 48, train_loss=0.0482, val_loss=0.0843\n",
      "Epoch: 49, train_loss=0.0476, val_loss=0.0821\n",
      "Epoch: 50, train_loss=0.0473, val_loss=0.0801\n",
      "Epoch: 51, train_loss=0.0468, val_loss=0.0782\n",
      "Epoch: 52, train_loss=0.0465, val_loss=0.0765\n",
      "Epoch: 53, train_loss=0.0461, val_loss=0.0750\n",
      "Epoch: 54, train_loss=0.0459, val_loss=0.0736\n",
      "Epoch: 55, train_loss=0.0457, val_loss=0.0723\n",
      "Epoch: 56, train_loss=0.0452, val_loss=0.0711\n",
      "Epoch: 57, train_loss=0.0448, val_loss=0.0700\n",
      "Epoch: 58, train_loss=0.0445, val_loss=0.0690\n",
      "Epoch: 59, train_loss=0.0444, val_loss=0.0680\n",
      "Epoch: 60, train_loss=0.0441, val_loss=0.0672\n",
      "Epoch: 61, train_loss=0.0439, val_loss=0.0663\n",
      "Epoch: 62, train_loss=0.0435, val_loss=0.0655\n",
      "Epoch: 63, train_loss=0.0433, val_loss=0.0648\n",
      "Epoch: 64, train_loss=0.0431, val_loss=0.0640\n",
      "Epoch: 65, train_loss=0.0426, val_loss=0.0634\n",
      "Epoch: 66, train_loss=0.0425, val_loss=0.0627\n",
      "Epoch: 67, train_loss=0.0423, val_loss=0.0620\n",
      "Epoch: 68, train_loss=0.0420, val_loss=0.0614\n",
      "Epoch: 69, train_loss=0.0416, val_loss=0.0608\n",
      "Epoch: 70, train_loss=0.0414, val_loss=0.0602\n",
      "Epoch: 71, train_loss=0.0412, val_loss=0.0596\n",
      "Epoch: 72, train_loss=0.0407, val_loss=0.0591\n",
      "Epoch: 73, train_loss=0.0404, val_loss=0.0585\n",
      "Epoch: 74, train_loss=0.0403, val_loss=0.0579\n",
      "Epoch: 75, train_loss=0.0401, val_loss=0.0574\n",
      "Epoch: 76, train_loss=0.0397, val_loss=0.0568\n",
      "Epoch: 77, train_loss=0.0395, val_loss=0.0563\n",
      "Epoch: 78, train_loss=0.0393, val_loss=0.0557\n",
      "Epoch: 79, train_loss=0.0390, val_loss=0.0552\n",
      "Epoch: 80, train_loss=0.0385, val_loss=0.0547\n",
      "Epoch: 81, train_loss=0.0382, val_loss=0.0541\n",
      "Epoch: 82, train_loss=0.0378, val_loss=0.0535\n",
      "Epoch: 83, train_loss=0.0373, val_loss=0.0530\n",
      "Epoch: 84, train_loss=0.0374, val_loss=0.0524\n",
      "Epoch: 85, train_loss=0.0369, val_loss=0.0518\n",
      "Epoch: 86, train_loss=0.0367, val_loss=0.0512\n",
      "Epoch: 87, train_loss=0.0362, val_loss=0.0507\n",
      "Epoch: 88, train_loss=0.0359, val_loss=0.0501\n",
      "Epoch: 89, train_loss=0.0356, val_loss=0.0495\n",
      "Epoch: 90, train_loss=0.0351, val_loss=0.0490\n",
      "Epoch: 91, train_loss=0.0350, val_loss=0.0484\n",
      "Epoch: 92, train_loss=0.0346, val_loss=0.0478\n",
      "Epoch: 93, train_loss=0.0339, val_loss=0.0472\n",
      "Epoch: 94, train_loss=0.0338, val_loss=0.0466\n",
      "Epoch: 95, train_loss=0.0334, val_loss=0.0460\n",
      "Epoch: 96, train_loss=0.0330, val_loss=0.0454\n",
      "Epoch: 97, train_loss=0.0326, val_loss=0.0448\n",
      "Epoch: 98, train_loss=0.0322, val_loss=0.0441\n",
      "Epoch: 99, train_loss=0.0318, val_loss=0.0435\n"
     ]
    }
   ],
   "source": [
    "# 학습 \n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 0\n",
    "loss_history = []\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "\n",
    "    train_loss_history = []\n",
    "    for data, target in train_dataloader:\n",
    "        # 데이터 GPU 보내기\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # print(data.shape, target.shape)\n",
    "\n",
    "        optimizer.zero_grad() # 초기화\n",
    "        pred = model(data) # 예측\n",
    "        loss = criterion(pred, target) # 손실 계산\n",
    "        loss.backward() # 역전파\n",
    "        optimizer.step() # 최적화함수 업데이트\n",
    "\n",
    "        # 손실 저장\n",
    "        train_loss_history.append(loss.item())\n",
    "\n",
    "    # Validation \n",
    "    model.eval()\n",
    "\n",
    "    val_loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_dataloader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            pred = model(data)\n",
    "            loss = criterion(pred, target)\n",
    "            val_loss_history.append(loss.item())\n",
    "    \n",
    "    # 출력\n",
    "    train_loss = float(np.mean(train_loss_history))\n",
    "    val_loss = float(np.mean(val_loss_history))\n",
    "\n",
    "    loss_history.append(train_loss)\n",
    "    print(f\"Epoch: {epoch}, train_loss={train_loss:.4f}, val_loss={val_loss:.4f}\")\n",
    "\n",
    "    # 학습 끝내는 조건\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss \n",
    "        patience = 0\n",
    "        torch.save(model.state_dict(), \"best.pth\")\n",
    "    else:\n",
    "        patience += 1\n",
    "        if patience >= 10:\n",
    "            break\n",
    "\n",
    "# 학습 저장\n",
    "torch.save(model.state_dict(), \"last.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83322214",
   "metadata": {},
   "source": [
    "## 7. 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "60f53740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(5,3))\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef348aad",
   "metadata": {},
   "source": [
    "## 8. 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.016013071210181806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:616: UserWarning: Using a target size (torch.Size([50, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\PythonProject\\poten_up09\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:616: UserWarning: Using a target size (torch.Size([44, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# Validation \n",
    "model.eval()\n",
    "\n",
    "test_loss_history = []\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        pred = model(data)\n",
    "        loss = criterion(pred, target)\n",
    "        test_loss_history.append(loss.item())\n",
    "\n",
    "print(float(np.mean(test_loss_history)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d320126",
   "metadata": {},
   "source": [
    "## 9. 예측 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c73f4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5443708300590515\n",
      "0.5440411567687988\n",
      "0.5419105291366577\n",
      "0.5394266843795776\n",
      "0.5370805263519287\n",
      "0.5351720452308655\n",
      "0.5340359807014465\n",
      "0.5336077809333801\n",
      "0.5340901017189026\n",
      "0.5352636575698853\n",
      "0.5369545221328735\n",
      "0.5393586754798889\n",
      "0.5418365001678467\n",
      "0.5436769723892212\n",
      "0.5457774996757507\n",
      "0.5484834313392639\n",
      "0.5509836673736572\n",
      "0.5534838438034058\n",
      "0.5556926131248474\n",
      "0.5574326515197754\n",
      "0.5588780641555786\n",
      "0.5619401931762695\n",
      "0.5669006705284119\n",
      "0.5730936527252197\n",
      "0.5817096829414368\n",
      "0.592652440071106\n",
      "0.6054180860519409\n",
      "0.6184474229812622\n",
      "0.6312522888183594\n",
      "0.6429064273834229\n",
      "0.6549912691116333\n",
      "0.6664295196533203\n",
      "0.6768994331359863\n",
      "0.6852744817733765\n",
      "0.6917572021484375\n",
      "0.6962064504623413\n",
      "0.699781060218811\n",
      "0.7025725245475769\n",
      "0.7048662900924683\n",
      "0.7062154412269592\n",
      "0.7078619599342346\n",
      "0.709464430809021\n",
      "0.7103044986724854\n",
      "0.7112170457839966\n",
      "0.7137157917022705\n",
      "0.7158250212669373\n",
      "0.7187166810035706\n",
      "0.7218688726425171\n",
      "0.7232668399810791\n",
      "0.7225819826126099\n",
      "0.7209780812263489\n",
      "0.7178977727890015\n",
      "0.7130271196365356\n",
      "0.707115888595581\n",
      "0.7001476287841797\n",
      "0.6930011510848999\n",
      "0.6861777901649475\n",
      "0.6787495613098145\n",
      "0.6701379418373108\n",
      "0.6629379391670227\n",
      "0.6564972996711731\n",
      "0.651369571685791\n",
      "0.6468070149421692\n",
      "0.6421867609024048\n",
      "0.6382219791412354\n",
      "0.6367070078849792\n",
      "0.637079119682312\n",
      "0.6384910345077515\n",
      "0.6416553258895874\n",
      "0.6451632976531982\n",
      "0.6494615077972412\n",
      "0.6543502807617188\n",
      "0.6595751047134399\n",
      "0.6650144457817078\n",
      "0.6703207492828369\n",
      "0.6753568649291992\n",
      "0.681049108505249\n",
      "0.6866212487220764\n",
      "0.6916008591651917\n",
      "0.6967490911483765\n",
      "0.7053599953651428\n",
      "0.7151072025299072\n",
      "0.724972128868103\n",
      "0.7370321750640869\n",
      "0.7501652240753174\n",
      "0.7635481953620911\n",
      "0.7763936519622803\n",
      "0.7881438732147217\n",
      "0.7998781800270081\n",
      "0.8118114471435547\n",
      "0.8227972388267517\n",
      "0.8334774374961853\n",
      "0.8424606919288635\n",
      "0.8498847484588623\n",
      "0.8524830937385559\n",
      "0.8484165668487549\n",
      "0.839282751083374\n",
      "0.8279578685760498\n",
      "0.8144758939743042\n",
      "0.7993895411491394\n",
      "0.782762885093689\n",
      "0.7673561573028564\n",
      "0.7528781294822693\n",
      "0.7391190528869629\n",
      "0.7270455360412598\n",
      "0.7173899412155151\n",
      "0.7095286846160889\n",
      "0.7029887437820435\n",
      "0.6972694993019104\n",
      "0.6914574503898621\n",
      "0.6864410638809204\n",
      "0.6823258996009827\n",
      "0.6785093545913696\n",
      "0.6769859790802002\n",
      "0.6769722700119019\n",
      "0.6775215268135071\n",
      "0.677724301815033\n",
      "0.6784977912902832\n",
      "0.6789471507072449\n",
      "0.679585337638855\n",
      "0.6792373061180115\n",
      "0.6786174774169922\n",
      "0.6773784756660461\n",
      "0.6759890913963318\n",
      "0.6743416786193848\n",
      "0.6725492477416992\n",
      "0.6711774468421936\n",
      "0.6691644191741943\n",
      "0.6663036942481995\n",
      "0.6626768112182617\n",
      "0.6583371758460999\n",
      "0.6535236835479736\n",
      "0.6486848592758179\n",
      "0.6438075304031372\n",
      "0.6383705735206604\n",
      "0.6325551271438599\n",
      "0.6274910569190979\n",
      "0.6226935386657715\n",
      "0.6177558302879333\n",
      "0.6116321086883545\n",
      "0.6038386821746826\n",
      "0.5945903062820435\n",
      "0.5848841667175293\n",
      "0.5776495933532715\n",
      "0.5723403096199036\n",
      "0.5680028200149536\n",
      "0.5647891759872437\n",
      "0.561987578868866\n",
      "0.5600609183311462\n",
      "0.5588973760604858\n",
      "0.5578140020370483\n",
      "0.557669997215271\n",
      "0.5581158995628357\n",
      "0.5594885945320129\n",
      "0.5611523389816284\n",
      "0.5632383823394775\n",
      "0.5658356547355652\n",
      "0.5682710409164429\n",
      "0.5717058181762695\n",
      "0.5756542086601257\n",
      "0.5801799893379211\n",
      "0.5847499370574951\n",
      "0.5892200469970703\n",
      "0.5937691926956177\n",
      "0.5989669561386108\n",
      "0.6036400198936462\n",
      "0.6078383922576904\n",
      "0.6110661029815674\n",
      "0.6133477091789246\n",
      "0.6149536371231079\n",
      "0.6158141493797302\n",
      "0.6164660453796387\n",
      "0.618178129196167\n",
      "0.6199991106987\n",
      "0.6211974024772644\n",
      "0.6219862699508667\n",
      "0.6220250129699707\n",
      "0.6216405630111694\n",
      "0.6216168999671936\n",
      "0.6204261779785156\n",
      "0.6188910007476807\n",
      "0.6171168088912964\n",
      "0.615152895450592\n",
      "0.6126854419708252\n",
      "0.6093859672546387\n",
      "0.6060540676116943\n",
      "0.6028746962547302\n",
      "0.5999932289123535\n",
      "0.5972379446029663\n",
      "0.5952531099319458\n",
      "0.5930603742599487\n",
      "0.5912981629371643\n",
      "0.5898094773292542\n",
      "0.5886605978012085\n",
      "0.588420033454895\n",
      "0.5881041288375854\n",
      "0.5879503488540649\n",
      "0.5877653360366821\n",
      "0.588388979434967\n",
      "0.5885469317436218\n",
      "0.5885565280914307\n",
      "0.5884738564491272\n",
      "0.5884549021720886\n",
      "0.5884169340133667\n",
      "0.5886914134025574\n",
      "0.5888186693191528\n",
      "0.5890716314315796\n",
      "0.589042603969574\n",
      "0.5899405479431152\n",
      "0.5936785936355591\n",
      "0.5992573499679565\n",
      "0.6064395308494568\n",
      "0.6152393221855164\n",
      "0.6243476867675781\n",
      "0.6340880393981934\n",
      "0.6427991390228271\n",
      "0.6512680053710938\n",
      "0.6592859625816345\n",
      "0.6666083335876465\n",
      "0.6733449697494507\n",
      "0.6799098253250122\n",
      "0.6877265572547913\n",
      "0.696089506149292\n",
      "0.7045906782150269\n",
      "0.7122557759284973\n",
      "0.7190282344818115\n",
      "0.7242246270179749\n",
      "0.7255164384841919\n",
      "0.7246015071868896\n",
      "0.7213200926780701\n",
      "0.7158270478248596\n",
      "0.7083024978637695\n",
      "0.6995476484298706\n",
      "0.6903250813484192\n",
      "0.6818866729736328\n",
      "0.6740713119506836\n",
      "0.6672930717468262\n",
      "0.6614712476730347\n",
      "0.6565160751342773\n",
      "0.6525524258613586\n",
      "0.6490704417228699\n",
      "0.6465219259262085\n",
      "0.6445845365524292\n",
      "0.643456220626831\n"
     ]
    }
   ],
   "source": [
    "X_test_ts = torch.FloatTensor(X_test)\n",
    "y_test_ts = torch.FloatTensor(y_test)\n",
    "\n",
    "# 예측값 저장\n",
    "pred_history = []\n",
    "for i in range(len(X_test_ts)):\n",
    "    with torch.no_grad():\n",
    "        data = X_test_ts[i].to(device)\n",
    "        pred = model(data.unsqueeze(dim=0))\n",
    "        print(pred.item())\n",
    "        pred_history.append(pred.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9bb616",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poten_up09",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
